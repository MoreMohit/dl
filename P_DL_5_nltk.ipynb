{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c546a66-4ba3-42e1-af54-b1492fa4267e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mohit/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/mohit/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Import Libraries\n",
    "import nltk, re, gensim\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "493b0d4c-ce53-485f-9a91-a6a584d18a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b) Input paragraph\n",
    "text = \"\"\"Alice opened the door and found that it led into a small passage.\n",
    "She looked into the beautiful garden and wished to go outside.\n",
    "But she could not get through the doorway and thought of shrinking like a telescope.\"\"\"\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "text = text.lower()  \n",
    "sentences = nltk.sent_tokenize(text) \n",
    "\n",
    "cleaned = []\n",
    "for s in sentences:\n",
    "    s = re.sub('[^a-z0-9 ]+', '', s) \n",
    "    cleaned.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e92dd4da-ba59-4513-b3f2-b1596f42c69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Tokens: [['alice', 'opened', 'door', 'found', 'led', 'small', 'passage'], ['looked', 'beautiful', 'garden', 'wished', 'go', 'outside'], ['could', 'get', 'doorway', 'thought', 'shrinking', 'like', 'telescope']]\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Tokenization and Stopword Removal\n",
    "tokens = [nltk.word_tokenize(s) for s in cleaned]\n",
    "sw = set(stopwords.words('english'))\n",
    "for i in range(len(tokens)):\n",
    "    tokens[i] = [w for w in tokens[i] if w not in sw]\n",
    "\n",
    "print(\"Cleaned Tokens:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "981979cd-1ced-447b-98c6-762e68e6a32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vocabulary: ['telescope', 'like', 'opened', 'door', 'found', 'led', 'small', 'passage', 'looked', 'beautiful', 'garden', 'wished', 'go', 'outside', 'could', 'get', 'doorway', 'thought', 'shrinking', 'alice']\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Train Word2Vec Model using CBOW\n",
    "model = gensim.models.Word2Vec(tokens, \n",
    "                               vector_size=50, \n",
    "                               window=5, \n",
    "                               min_count=1, \n",
    "                               sg=0)\n",
    "\n",
    "print(\"\\nVocabulary:\", list(model.wv.key_to_index.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcb1ccb1-0d42-48f7-b6e6-bcedbd6f19ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter 4 context words\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Context words:  alice door found small\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted Target Word(s):\n",
      "led\n",
      "small\n",
      "beautiful\n"
     ]
    }
   ],
   "source": [
    "# Step 6: User Input for Prediction\n",
    "print(\"\\nEnter 4 context words\")\n",
    "user_input = input(\"Context words: \").lower().split()\n",
    "\n",
    "# Predict the most likely target word\n",
    "predicted = model.predict_output_word(user_input, topn=3)\n",
    "\n",
    "print(\"\\nPredicted Target Word(s):\")\n",
    "for word, prob in predicted:\n",
    "    print(f\"{word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff7de74-acf0-437a-9355-26c1b1105f43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
